---
title: 2SLS standard errors and the delta-method
author: 'James'
date: '2017-10-07'
slug: delta-method-and-2SLS-SEs
categories: []
tags:
  - instrumental variables
  - delta method
header:
  caption: ''
  image: ''
---



<p>I just covered instrumental variables in my course on causal inference, and so I have two-stage least squares (2SLS) estimation on the brain. In this post I’ll share something I realized in the course of prepping for class: that standard errors from 2SLS estimation are equivalent to delta method standard errors based on the Wald IV estimator. (I’m no econometrician, so this had never occurred to me before. Perhaps it will be interesting to other non-econometrician readers. And perhaps the econometricians can point me to the relevant page in Wooldridge or Angrist and Pischke or whomever that explains this better than I have.)</p>
<p>Let’s consider a system with an outcome <span class="math inline">\(y_i\)</span>, a focal treatment <span class="math inline">\(t_i\)</span> identified by a single instrument <span class="math inline">\(z_i\)</span>, along with a row-vector of exogenous covariates <span class="math inline">\(\mathbf{x}_i\)</span>, all for <span class="math inline">\(i = 1,...,n\)</span>. The usual estimating equations are:</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp;= \mathbf{x}_i \delta_0 + t_i \delta_1 + e_i \\
t_i &amp;= \mathbf{x}_i \alpha_0 + z_i \alpha_1 + u_i.
\end{aligned}
\]</span></p>
<p>With a single-instrument, the 2SLS estimator of <span class="math inline">\(\delta_1\)</span> is exactly equivalent to the Wald estimator</p>
<p><span class="math display">\[
\hat\delta_1 = \frac{\hat\beta_1}{\hat\alpha_1},
\]</span></p>
<p>where <span class="math inline">\(\hat\alpha_1\)</span> is the OLS estimator from the first-stage regression of <span class="math inline">\(t_i\)</span> on <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(z_i\)</span> and <span class="math inline">\(\hat\beta_1\)</span> is the OLS estimator from the regression</p>
<p><span class="math display">\[
y_i = \mathbf{x}_i \beta_0 + z_i \beta_1 + v_i.
\]</span></p>
<p>The delta-method approximation for <span class="math inline">\(\text{Var}(\hat\delta_1)\)</span> is</p>
<p><span class="math display">\[
\text{Var}\left(\hat\delta_1\right) \approx \frac{1}{\alpha_1^2}\left[ \text{Var}\left(\hat\beta_1\right) + \delta_1^2 \text{Var}\left(\hat\alpha_1\right) - 2 \delta_1 \text{Cov}\left(\hat\beta_1, \hat\alpha_1\right) \right]. 
\]</span></p>
<p>Substituting the estimators in place of parameters, and using heteroskedasticity-consistent (HC0, to be precise) estimators for <span class="math inline">\(\text{Var}\left(\hat\beta_1\right)\)</span>, <span class="math inline">\(\text{Var}\left(\hat\alpha_1\right)\)</span>, and <span class="math inline">\(\text{Cov}\left(\hat\beta_1, \hat\alpha_1\right)\)</span>, it turns out the feasible delta-method variance estimator is <em>exactly</em> equivalent to the HC0 variance estimator from 2SLS.</p>
<div id="connecting-delta-method-and-2sls" class="section level3">
<h3>Connecting delta-method and 2SLS</h3>
<p>To demonstrate this claim, let’s first partial out the covariates, taking <span class="math inline">\(\mathbf{\ddot{y}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&#39;\mathbf{X}\right)^{-1}\mathbf{X}&#39;\right]\mathbf{y}\)</span>, <span class="math inline">\(\mathbf{\ddot{t}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&#39;\mathbf{X}\right)^{-1}\mathbf{X}&#39;\right]\mathbf{t}\)</span>, and <span class="math inline">\(\mathbf{\ddot{z}} = \left[\mathbf{I} - \mathbf{X}\left(\mathbf{X}&#39;\mathbf{X}\right)^{-1}\mathbf{X}&#39;\right]\mathbf{z}\)</span>. The OLS estimators of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\alpha_1\)</span> are then</p>
<p><span class="math display">\[
\hat\beta_1 = \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&#39;\mathbf{\ddot{y}}, \qquad \text{and} \qquad \hat\alpha_1 = \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&#39;\mathbf{\ddot{t}}.
\]</span></p>
<p>The HC0 variance and covariance estimators for these coefficients have the usual sandwich form:</p>
<p><span class="math display">\[
\begin{aligned}
V^{\beta_1} &amp;= \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{v}_i^2\right) \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \\
V^{\alpha_1} &amp;= \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{u}_i^2\right) \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \\
V^{\alpha_1\beta_1} &amp;= \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\left(\sum_{i=1}^n \ddot{z}_i^2 \ddot{u}_i \ddot{v}_i\right) \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\ddot{v}_i\)</span> and <span class="math inline">\(\ddot{u}_i\)</span> are the residuals from the regressions of <span class="math inline">\(\mathbf{\ddot{y}}\)</span> on <span class="math inline">\(\mathbf{\ddot{z}}\)</span> and <span class="math inline">\(\mathbf{\ddot{t}}\)</span> on <span class="math inline">\(\mathbf{\ddot{z}}\)</span>, respectively. Combining all these terms, the delta-method variance estimator is then</p>
<p><span class="math display">\[
V^{\delta_1} = \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\left[\sum_{i=1}^n \ddot{z}_i^2\left(\ddot{v}_i^2 + \hat\delta_1^2 \ddot{u}_i^2 - 2 \hat\delta_1\ddot{u}_i \ddot{v}_i\right)\right] \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}.
\]</span></p>
<p>Remember this formula because we’ll return to it shortly.</p>
<p>Now consider the 2SLS estimator. To calculate this, we begin by taking the fitted values from the regression of <span class="math inline">\(\mathbf{\ddot{t}}\)</span> on <span class="math inline">\(\mathbf{\ddot{z}}\)</span>:</p>
<p><span class="math display">\[
\mathbf{\tilde{t}} = \mathbf{\ddot{z}}\left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1}\mathbf{\ddot{z}}&#39;\mathbf{\ddot{t}} = \mathbf{\ddot{z}} \hat\alpha_1.
\]</span></p>
<p>We then regress <span class="math inline">\(\mathbf{\ddot{y}}\)</span> on <span class="math inline">\(\mathbf{\tilde{t}}\)</span>:</p>
<p><span class="math display">\[
\hat\delta_1 = \left(\mathbf{\tilde{t}}&#39;\mathbf{\tilde{t}}\right)^{-1} \mathbf{\tilde{t}}&#39; \mathbf{\ddot{y}}.
\]</span></p>
<p>The HC0 variance estimator corresponding to the 2SLS estimator is</p>
<p><span class="math display">\[
V^{2SLS} = \left(\mathbf{\tilde{t}}&#39;\mathbf{\tilde{t}}\right)^{-1} \left(\sum_{i=1}^n \tilde{t}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\tilde{t}}&#39;\mathbf{\tilde{t}}\right)^{-1},
\]</span></p>
<p>where <span class="math inline">\(\tilde{e}_i = \ddot{y}_i - \ddot{t}_i \hat\delta_1\)</span>. Note that these residuals are calculated based on <span class="math inline">\(\ddot{t}_i\)</span>, the <em>full</em> treatment variable, not the fitted values <span class="math inline">\(\tilde{t}_i\)</span>. The full treatment variable can be expressed as <span class="math inline">\(\ddot{t}_i = \tilde{t}_i + \ddot{u}_i\)</span>, by which it follows that</p>
<p><span class="math display">\[
\tilde{e}_i = \ddot{y}_i - \tilde{t}_i \hat\delta_1 - \ddot{u}_i \hat\delta_1.
\]</span></p>
<p>But <span class="math inline">\(\tilde{t}_i \hat\delta_1 = \ddot{z}_i \hat\alpha_1 \hat\delta_1 = \ddot{z}_i \hat\beta_1\)</span>, and so</p>
<p><span class="math display">\[
\tilde{e}_i = \ddot{y}_i - \ddot{z}_i \hat\beta_1 - \ddot{u}_i \hat\delta_1 = \ddot{v}_i - \ddot{u}_i \hat\delta_1.
\]</span></p>
<p>The 2SLS variance estimator is therefore</p>
<p><span class="math display">\[
\begin{aligned}
V^{2SLS} &amp;= \left(\mathbf{\tilde{t}}&#39;\mathbf{\tilde{t}}\right)^{-1} \left(\sum_{i=1}^n \tilde{t}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\tilde{t}}&#39;\mathbf{\tilde{t}}\right)^{-1} \\
&amp;= \left(\hat\alpha_1^2 \mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \left(\sum_{i=1}^n \hat\alpha_1^2 \ddot{z}_i^2 \tilde{e}_i^2 \right) \left(\hat\alpha_1^2 \mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \\
&amp;= \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \left(\sum_{i=1}^n \ddot{z}_i^2 \tilde{e}_i^2 \right) \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \\
&amp;= \frac{1}{\hat\alpha_1^2}\left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1} \left[\sum_{i=1}^n \ddot{z}_i^2 \left(\ddot{v}_i - \ddot{u}_i \hat\delta_1\right)^2 \right] \left(\mathbf{\ddot{z}}&#39;\mathbf{\ddot{z}}\right)^{-1},
\end{aligned}
\]</span></p>
<p>which agrees with <span class="math inline">\(V^{\delta_1}\)</span> as given above.</p>
</div>
<div id="so-what" class="section level3">
<h3>So what?</h3>
<p>If you’ve continued reading this far…I’m slightly amazed…but if you have, you may be wondering why it’s worth knowing about this relationship. The equivalence between the 2SLS variance estimator and the delta method interests me for a couple of reasons.</p>
<ul>
<li>First is that I had always taken the 2SLS variance estimator as being conditional on <span class="math inline">\(\mathbf{t}\)</span>–that is, not accounting for random variation in the treatment assignment. The delta-method form of the variance makes it crystal clear that this isn’t the case—the variance <em>does</em> include terms for <span class="math inline">\(\text{Var}(\hat\alpha_1)\)</span> and <span class="math inline">\(\text{Cov}(\hat\beta_1, \hat\alpha_1)\)</span>.</li>
<li>On the other hand, there’s perhaps a sense that equivalence with the 2SLS variance estimator (the more familiar form) validates the delta method variance estimator—that is, we wouldn’t be doing something fundamentally different by using the delta method variance with a Wald estimator. For instance, we might want to estimate <span class="math inline">\(\alpha_1\)</span> and/or <span class="math inline">\(\beta_1\)</span> by some other means (e.g., by estimating <span class="math inline">\(\alpha_1\)</span> as a marginal effect from a logistic regression or estimating <span class="math inline">\(\beta_1\)</span> with a multi-level model). It would make good sense in this instance to use the Wald estimator <span class="math inline">\(\hat\beta_1 / \hat\alpha_1\)</span> and to estimate its variance using the delta method form.</li>
<li>One last reason I’m interested in this is that writing out the variance estimators will likely help in understanding how to approach small-sample corrections to <span class="math inline">\(V^{2SLS}\)</span>. But I’ll save that for another day.</li>
</ul>
</div>
