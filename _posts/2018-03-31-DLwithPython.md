---
layout: post
title: Deep Learning with Python を読んだ
categories: ['ML paper']
---
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


### TL;DR
- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) を読んだ
- よく書かれている本で、特に初学者〜中級者が Keras を使ってモデル構築ができるようになるには最適
- 扱っているトピック自体は他の本と比べてそこまで変わっていないが、一つ一つの質は高い
- 個人的には Keras の実装の話などをもっとして欲しかった

Keras 作者の Chollet 氏が書いた deep learning 本ということで、どんな内容なんだろうと思って読んでみた。

結論から言うととてもよく書けている本で、対象読者は Keras を使って deep learning を始めたい（始めてみた）という人かと思う。
どんな経緯で出した本かとかそういうのは全然知らないが、deep learning が使えるようになるための getting started となる決定版を書いたぞ、という印象を受けた。
自分としては著者にしか書けない Keras の詳しい話が読みたかったなと思うが、そういうのは対象読者じゃなかったということですね、残念。

全体を通して著者がよく知っている（もしくはよく調べた）情報が著者の言葉で語られているというのは読んでいて心地が良かった。
数式を出さないのは個人的には悲しいところだが、それでも正しい説明となるように工夫をしている点は随所に感じられた。
convlution の図示説明や著者考案の Xception 周りの channel 方向と space 方向の扱いの説明などは、（言わずもがなであるが）著者の理解がしっかりしていてかつ気をつけて論を展開したということが伺える。

本は400ページに満たないが、その中で基礎の説明から始まり、画像・テキストを両方取り扱い、最後に生成モデルまで紹介する、というのはよくまとめられていると思う。
最後の生成モデルは面白そうなトピックをガッと詰め込んだという感じも否めないが、とにかくこの本を読んで何も新しい知識が得られないという人はかなり少数派ではないかなと感じる。

Keras を最低限は使ったことがある、という人にも Chapter 7 の情報は有用であろう。
functional API を用いたより複雑なモデルの構築や callback の使用方法などが記載されている。

結構 code が出てくるが、その補足説明がしっかりしているのも学び始めの人には嬉しいところだと思う。
この手の本は写経して動くことを確認したら終わり、となりがちだが、それよりは一歩踏み込んで意図が理解しやすい。
それと notebook を notebook っぽく作ってるところ（情報の残し方とか実行可能性とか）もいいね。

以降で各 chapter に関するコメントをする。


### Chapter 1. What is deep learning?
AI/ML/DL の違いから入り、DL以外のモデル（GBDTなど）も交えつつ簡単な歴史の説明がなされる。
かなりさらりとした感じだが、gradient boosting が "nonperceptual" なデータに対する best なものの１つであるということにも言及している。

LSTM が1997年考案なのになぜ deep learning が威力を発揮するまで長い時間が掛かったのか、という疑問に関しても、ハードウェアやデータやアルゴリズムという観点から説明がなされている。
この辺は自分が本を書くときに考えてまとめた内容とほぼ同義だったので、書くとしたらこんな感じになるよなぁと思った。

Deep learning は {simplicity, scalability, versatility and reusability} の観点から今後も使われていくだろう、というのはなかなか綺麗なまとめ。


### Chapter 2. Before we begin: the mathematical building blocks of neural networks
扱う tensor とその operation に関する基本的な説明。
そんなに特筆すべき点はないと思うが、broadcasting や tensor dot も説明されていて、必要最低限のものをコンパクトにまとめたという印象。
SGD の説明も入るが、loss に関する部分の説明などはちょっと薄く、Chapter 4. と合わせて読まないと馴染みがない人は消化不良になる恐れはあるかも。


### Chapter 3. Getting started with neural networks
Keras の概略説明とデータ準備とモデル作成・学習の一連の流れを説明している章。
てっきり MNIST かと思ったが、 IMDB, reuters, boston housing のデータを使った分類と回帰が題材になっていてそこでモデリングに必要な要素が色々と紹介されるという形。

モデルパラメタをいじって実験してみよということも書かれているが、こういう例で変えてもそんなに違いが出なかったりもするので、この辺の違いを身に付けていくのは結構大変だよなぁ。
自分に良い案があるわけではないのだが、もっと違いが顕著に出やすい toy problem にして振る舞いを確認するというのは一個の手段かと思う。

ちなみに The rmsprop optimizer is generally a good enough choice, what ever your problem. という一文があったりしてなかなか力強い。


### Chapter 4. Fundamentals of machine learning
MLの基本的な説明と Chapter 3. の内容を抽象化して workflow をまとめている。

出てくる項目はそんなに特別なものはないが、一つ一つの説明は標準的な本よりしっかりと書かれている印象。
時間順序や冗長性がある場合の注意点、正規化ではデータを小さい値にしてかつ homogeneous にする、dropout に関する Hinton 氏の銀行員対応の例（銀行員が共謀して銀行に詐欺行為を働かないように人員を頻繁に入れ替える）、などなど。

metric に関しては kaggle を参照せよ、という辺りは kaggle の実用面での有用性をうまく切り出そうという感じかと思うが、知らない人はこの情報だけ与えられても厳しそうではある。


### Chapter 5. Deep learning for computer vision
CNNの説明に関しては、数式は登場しないが、図で適切に channel 方向の処理が示されたりしていて説明の質は入門書の中では高い。

scratch からの学習や pre-trained model を使った学習が一通り説明されていて単純な classification においては十分ではないだろうか。
個人的には fine-tuning の明確な説明が書いてあるのが良かった。
著者によると「pre-trained model に追加した層のみ学習した後に、追加した層とそれに近いいくつかの層を学習する」という定義だった。
これがどれくらい一般的な定義かは知らないが、追加した層のみの学習と明確に使い分けている説明を自分は聞いたことがなかったので、意識的に説明してくれるのは有り難い。

可視化に関しても結構厚く取り扱われていて、これもやったことない人にとってはなかなか良いトピックだと思う。
可視化の一部をするためだけに opencv 使っている、という点はちょっとアレだが。


### Chapter 6. Deep learning for text and sequences
この本を読んでみて一番思ったのは「結構テキストデータを扱ってるじゃん」というもの。
画像が中心かなと勝手に思っていたので、テキストに関してもちゃんと取り扱っているのは凄いなと思った。

テキスト特有の前処理（one-hot encoding は当然として、embedding に加えて hashing trick も説明）をしっかり説明しているのは良い点。

ただし LSTM の説明はこれでは結構厳しいと思うんですがどうでしょう（自分の英語読解力の問題の可能性あり）。
ベルトコンベアの例などは直感的でいいけども、LSTM に関しては多くの人は他の文献にあたる必要がありそう。

それと問題自体が絶対に RNN を使った方がいいという類のものじゃないかなというのは少し気になる。
IMDB の classification は他のモデルの方がいいだろうし、気温予測も baseline からの差が出づらかったりして難しそう。
言語処理で使うのが王道（だがさすがに本の一章で扱うには厳しい）なので、興味がある人はそっちをやってみましょうという感じかな。


### Chapter 7. Advanced deep-learning best practices
この章は結構進んだ内容が書いてあって自分にとっても知らないことがいくつかあった。

functional API を使ったより複雑なトポロジーの構造を作る方法（実用的には multi input もしくは multi output が重要）や callback の使い方などは多くの人にとって役に立つ情報だろう。
それと Xception の説明（とそれに通ずる channel 方向と space 方向の取り扱い）は著者だけあって情報が濃い。
1*1 convolution とか depthwise convlution もそのコンテキストとうまくマッチさせて説明してる。
個人的には channel reduction 的な意味での説明があまりなされてないのがやや不満だが。

ちょっと異質なのは batch renormalization がコラムで紹介されていることだろう。
なんでこんなに新しい内容が特別に推されているかはちょっと分からない。
本の内容的にもこれの必要性は感じないので、個人的に好きか、考案者と仲がいいか、くらいしか思い浮かばない（別にどうでもいいことではあるのだが）。


### Chapter 8. Generative deep learning
この章は生成モデルのいくつかの具体例に関して、簡単な説明と実際のコードを提供するという感じである。
驚くべきことに text generation, style transfer, deep dream, VAE, GAN を取り扱っているのである。ヤバい。

代償として、それぞれの説明は初見で理解することはほぼ不可能だと思われる。
恐らく著者の気持ちとしては、主要な話題になっている生成モデルにも触れてもらって（code から入ってもらって）、動かしたことがあるという経験を与えるのが目的なんだろう。
言うのは楽だが code を準備する方は結構大変な作業であって、ちゃんと準備して凄いなぁと思う。


### Chapter 9. Conclusions
結構しっかりした本の内容のまとめだけに留まらず、deep learning の限界という観点での adversarial example の紹介や、汎化性能、deep learning の将来的な方向性などの興味深い話も載っている。
より進んだトピックに興味がある人はここで登場したものを深堀りしていくのもよさそう。


## まとめ
Deep Learning with Python を読んだ。
初学者〜中級者にとって非常に有用な本であることは間違いないと思う。
この内容の充実ぶりで、平易だが適当ではない説明がなされている、というのは著者の費やした時間が伺える。凄い。

ただし個人的には作者にしか書けない Keras の中身の話とかが知りたかったなという気持ち。
まあ偉そうなこと言って自分が以前に書いた本も自分にしか書けない内容を書けていないわけで、次書くなら自分が読んでも楽しい本を書けということですね。

---
---
<br>

