---
layout: post
title: Tutorial&#58 Creating a Deep Learning Heroku Python/Flask App to use on a Static Jekyll Site 
---

Often times, especially with side projects you're really proud of, a simple blog post isn't enough to showcase a model you've spent months developing. I created one [here](trap-generator.zeager.xyz) for a trap rap lyric generation model. This tutorial will take you through the various steps needed to create your own machine learning Heroku app on a static site like this one (a Jekyll site hosted on Github). 

**Step 0: Train Your Model**

Of course, in order to utilize your model in a web app, you'll need to first train your model. In my case, since I had a neural network *and* a word2vec model, and both of them had to be trained prior to creating the web app.

**Step 1: Create a Git repository for the project**

The easiest way to deploy to Heroku is to use a Git repository, so you'll need to create a Git repository in the folder where all of your files for the application will live including the trained models. 

**Step 2: Install Flask and set up your Flask application**

Next, you'll need to download flask using pip or whatever python package manager you prefer.

{% highlight shell %}
pip install flask
{% endhighlight %}

And now you'll have to do several things within your python app `app.py`. First, import the necessary modules and initialize the flask app.

{% highlight python %}
import numpy as np
import flask
from flask import request, render_template, flash
import io
import keras
from gensim.models import Word2Vec
import re

app = flask.Flask(__name__)
app.config.from_object(__name__)
{% endhighlight %}

**Step 4: Load Trained Model**

Now we need to set up some of the necessary functions for my app. Because my app was a text generation application, my full code may be way more complicated than you'll need. At the very least, you'll definitely need a function that loads your model like I have below. You *must* have the models set up as global variables in order for the prediction code to utilize the models in its predictions.

{% highlight python %}
def load_model():
    #load word 2 vec model
    global w2vmodel
    w2vmodel = Word2Vec.load('word2vec_model')
    w2v_weights = w2vmodel.wv.syn0
    global model
    model = lstm_model(num_layers, dropout, layer_size, w2v_weights, max_seq_length)
    model.load_weights('model/model_dropout0.05_num_layers_2_layersize_512_batch_size_64max_seq_length6_weights.h5', by_name=True)
{% endhighlight %}

**Step 3: Set up GET and POST methods**

After you create that function and any other helper functions your model needs to predict with new data, you need to set up the `GET` and `POST` methods. In the code below, we use the request.form module from Flask to define our html form class. This is served through our `GET` method.

{% highlight python %}
class ReusableForm(Form):
    seed = TextField('Seed:', validators=[validators.required()])
    
@app.route("/", methods=["GET"])

def serve_form():
    return render_template("form.html", form=ReusableForm(request.form))
{% endhighlight %}

Now of course, we don't have a `form.html` file yet! I used a template to create mine, but for this simple example, let's use a basic form.html file with just the input fields we need. In my case, I need three things from the user to output text: temperature (this allows you to select how diverse/creative the model will get with the output), the seed text, and the length that the user wants the generated text to be. 

{% highlight html %}
<html>
    <head>
        <title>Trap Music Demo</title>
    </head>
    <body>
      <h1>Trap Music Generator</h1>
        <form action="/" method="POST">
            {{ form.csrf }}

            <div>
              <input placeholder="temperature (0.01 to 1)" class="form-control" name="temperature"></input>
              <input placeholder="generated text length" class="form-control" name="length"></input>
            </div>
            <div>
              <textarea rows="50" cols="50" class="form-control" placeholder="seed text" name="seed"></textarea>


            </div>

            <div class="btn btn-success">
                <input type="submit" value="Submit" />
            </div>
        </form>
    </body>
</html>
{% endhighlight %}

Now, after the user has submitted the necessary information on `form.html`, we'll need to use a `POST` method to give the results to the user. This simple post method first loads the model using our `load_model` function defined in step 4, and then defines the form using the ReusableForm class created at the beginning of this step. You must define all the necessary variables that were submitted in the form using the names defined in the html, e.g. `seed=request.form['seed']`. Now, using the render_template function imported from flask, you can serve the generated text in the `success.html` form.


{% highlight python %}
@app.route("/", methods=['POST'])
def generate_text():
    load_model()
    global w2vmodel
    w2v_weights = w2vmodel.wv.syn0

    form = ReusableForm(request.form)
    print(form.errors)

    if flask.request.method =='POST':
        seed=request.form['seed']

        length=int(request.form['length'])
        temp=float(request.form['temperature']
        
        # since it was unnessarily complicated, I skipped the code that produced the
        # generated text (called generated) that will be returned by the function

        return render_template('success.html', generated=generated)
{% endhighlight %}

Of course, you'll need to define the `success.html` form, just as we did with `form.html`. 

{% highlight html %}
<html>
    <head>
        <title>Trap Music Demo</title>
    </head>
    <body>
      <h1>Trap Music Generator</h1>
        <pre>
          {{ generated }}
        </pre>
    </body>
</html>
{% endhighlight %}

The only real interesting part of this html form is the inclusion of the `{{ generated }}`, which serves as a placeholder for the generated text returned by the model.

**Step 4: Run the Flask server locally to test**
We can now set up the flask server locally to see if everything is working correctly. When you run the python app at the command line, you should get a localhost link, where you can try out your `GET` and `POST` forms to make sure everything is working correctly. Thecode below sets up the `__main__` module to load the model and run the application locally. 

{% highlight python %}
if __name__ == '__main__':
    print("* Loading Keras model and Flask starting server..."
        "please wait until server has fully started")
    load_model()
    app.run()
{% endhighlight %}

If you've run into any issues with the python code above, I've uploaded my full code to Github [here](https://github.com/frankiezeager/trap_generator/blob/master/app.py). It's a little more complicated because it includes my full prediction code, but it might help you organize your code.

**Step 5: Set up a Heroku Account and download Heroku CLI**

Head on over to [the heroku site](www.heroku.com) and create a free account. Now, you *may* find that you may need more memory than the free tier depending on the model (I certainly did), but you can upgrade your payment information later if find the free tier apps too slow or unreliable for your use case.  After you create an account, download and install the Heroku Command Line Interface (CLI). Then, after you install the CLI, head over to your command line and log in to heroku.

{% highlight shell %}
$ heroku login
  Enter your Heroku credentials.
  Email: python@example.com
  Password:
  ...
{% endhighlight %}

**Step 6: Deploy your Flask application as a Heroku app**

 1.  Install gunicorn. Since Heroku expects your application to start its own server, we will use gunicorn for that task. Just use pip to install it.
 {% highlight python %}
 pip install gunicorn
 {% endhighlight %}
 
 2. Navigate over to your git repository created in step 1 and create a `requirements.txt` file, which will tell Heroku all of the requirements that your app needs E.g., for my app I needed the following (yours may be a little different):
 ```Flask
gunicorn
keras
numpy
pandas
gensim
tensorflow
wtforms
h5py
```

3. In a text editor, you'll need to create a `Procfile`. The only thing you need to include in this file is the following, which will tell the app to spin up a gunicorn server.

```web: gunicorn app:app --log-file=-```


4. Create a `runtime.txt` file. The only thing you'll need to include in this is the version of python your app needs. For example, mine includes the following:

```python-3.6.4```

5. Create your heroku app. Heroku will generate a random name for your application, and will also create a git remote branch called heroku.
{% highlight shell %}
$ heroku create
{% endhighlight %}

6. Push your code to Heroku
{% highlight shell %}
$ git add .
$ git commit -m "initial commit"
[master 62513afzz] initial commit
$ git push heroku master
Counting objects: 7, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (7/7), done.
Writing objects: 100% (7/7), 1.72 KiB | 0 bytes/s, done.
Total 7 (delta 1), reused 0 (delta 0)
remote: Compressing source files... done.
remote: Building source:
remote: 
remote: -----> Python app detected
remote: -----> Installing pip
remote: -----> Installing requirements with pip
remote: 
remote: -----> Discovering process types
remote:        Procfile declares types -> web
remote: 
remote: -----> Compressing...
remote:        Done: 269.4M
remote: -----> Launching...
remote:        Released v60
remote:        https://shielded-river-87644.herokuapp.com/ deployed to Heroku
remote: 
remote: Verifying deploy... done.
To https://git.heroku.com/shielded-river-87644.git
   05f65c1..62513af  master -> master

{% endhighlight %}

Hooray, you're done! You can see your app at the link provided after pushing the code. If you have a custom domain for your Jekyll-hosted site (not a github.io site), then you can use your DNS to set up a CNAME alias for your application.
