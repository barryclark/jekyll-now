---
layout: post
title: 機械学習をやる上で線形代数のどのような知識が必要になるのか
categories: ['Machine Learning']
---

### TL;DR
- 「機械学習をやるなら線形代数はやっとけ」的な話が出るけど具体的な話があまり見当たらない
- 研究でなく実務レベルで機械学習を扱う場合にどのような線形代数の知識が必要になるのか考えてみた
- 高校でやるベクトル・行列＋αくらいあれば概念的には十分で、計算が苦じゃない基礎体力が重要では？
<br>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

機械学習が流行ることで、機械学習に必要な数学的基礎にも話が及ぶことが多くなってきている。
特に、線形代数や微積に関しては基礎を押さえとけみたいなことを言う人が結構いる気がする。
中身のない話をしたい場合はまあそれだけでもいいのだけれど、具体的に何が必要になるのかを説明してくれてる人はあまりいない。少なくとも自分の観測範囲では。
レベル感が様々なので万人に通用する議論はできないのはしょうがないが、「自分としてはこれは必要だと思っている」みたいな意見は聞いてみたい。

自分の考えはどうだろう、ということで線形代数を対象としてちょっと考えてみる。
研究でなく業務で機械学習を道具として使うという人をターゲットに考えてみる。
道具として使うと言っても有効に使うために重要な能力はもっと他にあると思っているが、あくまで線形代数に絞って考える。

### 必要だろ！というもの
ベクトルの基本的な取り扱いは外せない。
内積や一次独立とか。

行列の基本的な演算も必要だろう。
行列の掛け算が分かりません、というのはさすがに厳しいと思う。

同じように逆行列や固有値も知らないと難しい場面が多いのではないだろうか。
ただしこの辺りまでは高校の数学をやっていればカバーできているので復習すれば大丈夫だろう。
最近では行列が削除されてる？おっさんだから分かりません。

ちょっと微積と被るが、ベクトルによる微分とか行列による微分、というのも避けては通れない。
ここは慣れがない人にとっては辛い部分で、ある程度の訓練が必要そう。

ランク辺りは意見が割れるかも。
正則でない場合は当然よく現れるのでムーア・ペンローズ逆行列とかそれに類する内容は理解しているとよいかもしれない。

テンソルに関しては双対とか多重線形性とか難しい概念は必要ない。
行列が2階のテンソル、くらいの意味で階数が上がった時にも基本的な演算が理解・実行できれば十分。

あれ？ひょっとして内容としてはこれくらいかも？
色んな概念を知ることよりも、この辺りを手を動かして計算して基礎体力をつける方が有益そう。

### 必要なの？というもの
上記の内容を見ると、いわゆる大学で初めて触れる線形代数の内容はそこまで入ってないことに気付く。
いや、上記内容もやるか。ただ高校のベクトルや行列の話から概念としてとても新しいものはない、みたいな感じ？（完全に昔の話を忘れてるのでそうじゃないかも）

準同型定理とか次元定理とかジョルダン標準系とかグラム・シュミットの直交化とか、線形代数の講義で必ず出くわすやつらはほとんどの場合いらない。
ベクトル空間の定義なんかも持ち出す必要性が生じることがほぼない。

機械学習の具体例として、SVMとか真面目にやるなら再生核ヒルベルト空間が必要だろ、と怒る人がいるかもしれない。
自分はそういうのも好きな方なので勉強したけど、自分以外の人からは聞いたことは（学会以外では）ほぼない。

うーむ、線形代数と聞いて自分が典型的に思い浮かべるものはそんなに必要ないのでは？
みんなどういう意味で「線形代数はやっとけ」と言っているのだろうか？

## まとめ
機械学習やるなら線形代数が必要、という話を自分なりに考えてみた。

概念的には高校のベクトル・行列＋αくらいで、むしろその範囲で手を動かして慣れておく方が重要な気がする。
みんなどういう意味で言ってるのか教えて欲しい。

---
### 20180416 追記
他人の意見を目にして思ったことを追記しておく。

まず、自分が結論づけた「高校のベクトル・行列＋αで良さそう」というのは確実に誤りだった。
固有値や固有ベクトルは高校ではやらないけど欠かせない重要な概念だし、行列に関しては自分のときはあったかもしれないけど今はないのだから敷居が一気に高くなっているだろう。

自分の中で修正した結論としては「行列演算と逆行列、固有値・固有ベクトル、実対称行列の基本的性質」などを理解した上でかつ手を動かして計算する」くらいは必要になり、そしてそれは典型的には大学の線形代数を１コマ履修してガリガリ計算するくらいに相当しそう。
その上で3階以上のテンソルの計算、これは抽象的な概念は必要でなく有り体に言ってしまえば多次元配列の計算、に慣れておきたい。
これは深層学習で代表されるように多次元配列を扱うことが多いので、どの次元で和を取っているかとかで混乱しないためである。

一方でやはり抽象的な概念や定式化が必要になることは稀だと思う。
なので、線形代数が必要だからと言われて佐武一郎の「線形代数学」を読むのは適してない場合が多くて、マセマ本と演習（ジョルダン標準系とかはスキップしてよさそう）とかの方が適しているだろう。

その他思ったこと。

多変量解析で扱う範囲が分かっていれば十分なのでは、という意見がいくつかあってそれはそうかもしれないと思った。
行列・ベクトル表示と成分表示の行き来をして慣れれば、多次元配列を扱う場合も混乱しにくそう。

疎行列の取り扱いに重要だろうというのもどこかで見たが、行列演算の基礎が分かっていれば疎行列の計算を実直にやるのは非効率なのは理解できるし、ライブラリの実装に手を入れなければならないほどの事態はあまりなさそうだ。

数学記号のハードルが高い、というのはなるほどなぁと思った。
コードを読むのに慣れが必要なように、数式を読むのにも慣れが必要なので、これは本気になってやるしかなさそう。
どこかの情報をつまみ食いして理解しようとしても困難が生じるので、何かしら体系的にまとまった本を根気よく読むとかをしないと身に付きづらい。
その時にどの本がベストなのかということは自分は知らない。

自分にとって残念だったのはそんなに具体的な話がなかったことだ。
中身のない話が嫌だったので線形代数の具体的な話にフォーカスしたのに、人によって違うとか必要になったらやればいいとか、情報量がほぼゼロの議論が展開されるのは虚しさがある。
「自分はこう思う」とか「自分が線形代数という言葉を使う時は典型的にこういうトピックが含まれているものとして使う」とか、そういうのが聞ければ満足だったんだけどなぁ。
まあウェブ上で議論が噛み合わないのはお互い様なのでやむなし。

---
---
<br>

